{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the csv data in a dataframe\n",
    "DATA_PATH=\".//dataset//metabric\"\n",
    "DATA_NAME=\"featSurv.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_raw_data(data_path, data_name):\n",
    "    csv_path = os.path.join(data_path, data_name)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "df=load_raw_data(DATA_PATH,DATA_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        ID  age_at_diagnosis  size  lymph_nodes_positive  grade  \\\n",
       "0  MB-0000             75.65  22.0                  10.0    3.0   \n",
       "1  MB-0002             43.19  10.0                   0.0    3.0   \n",
       "2  MB-0005             48.87  15.0                   1.0    2.0   \n",
       "3  MB-0006             47.68  25.0                   3.0    2.0   \n",
       "4  MB-0008             76.97  40.0                   8.0    3.0   \n",
       "\n",
       "  histological_type ER_IHC_status ER.Expr PR.Expr  HER2_IHC_status  ...  \\\n",
       "0               IDC           pos       +       -              NaN  ...   \n",
       "1               IDC           pos       +       +              NaN  ...   \n",
       "2               IDC           pos       +       +              NaN  ...   \n",
       "3               IDC           pos       +       +              0.0  ...   \n",
       "4               IDC           pos       +       +              NaN  ...   \n",
       "\n",
       "  NOT_IN_OSLOVAL_P53_mutation_status NOT_IN_OSLOVAL_P53_mutation_type  \\\n",
       "0                                NaN                              NaN   \n",
       "1                                MUT                         MISSENSE   \n",
       "2                                NaN                              NaN   \n",
       "3                                NaN                              NaN   \n",
       "4                                 WT                              NaN   \n",
       "\n",
       "  NOT_IN_OSLOVAL_P53_mutation_details  \\\n",
       "0                                 NaN   \n",
       "1                      MB-AD-0002+ex5   \n",
       "2                                 NaN   \n",
       "3                                 NaN   \n",
       "4                                 NaN   \n",
       "\n",
       "                         NOT_IN_OSLOVAL_Pam50Subtype  \\\n",
       "0                                             Normal   \n",
       "1  6+chr17:7519122+12521A>AC+178H>H/P+MISSENSE+FR+FR   \n",
       "2                                               LumB   \n",
       "3                                               LumB   \n",
       "4                                               LumB   \n",
       "\n",
       "  NOT_IN_OSLOVAL_IntClustMemb  NOT_IN_OSLOVAL_Site  NOT_IN_OSLOVAL_Genefu  \\\n",
       "0                         NaN                    1                    NaN   \n",
       "1                        LumA                    4                      1   \n",
       "2                         NaN                    1                    NaN   \n",
       "3                         NaN                    1                    NaN   \n",
       "4                           9                    1  ER+/HER2- High Prolif   \n",
       "\n",
       "              x_Prolif  time status  \n",
       "0                  NaN  2999      0  \n",
       "1  ER+/HER2-HighProlif  1484      0  \n",
       "2                  NaN  3053      0  \n",
       "3                  NaN  1721      0  \n",
       "4                  NaN  1241      1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>age_at_diagnosis</th>\n      <th>size</th>\n      <th>lymph_nodes_positive</th>\n      <th>grade</th>\n      <th>histological_type</th>\n      <th>ER_IHC_status</th>\n      <th>ER.Expr</th>\n      <th>PR.Expr</th>\n      <th>HER2_IHC_status</th>\n      <th>...</th>\n      <th>NOT_IN_OSLOVAL_P53_mutation_status</th>\n      <th>NOT_IN_OSLOVAL_P53_mutation_type</th>\n      <th>NOT_IN_OSLOVAL_P53_mutation_details</th>\n      <th>NOT_IN_OSLOVAL_Pam50Subtype</th>\n      <th>NOT_IN_OSLOVAL_IntClustMemb</th>\n      <th>NOT_IN_OSLOVAL_Site</th>\n      <th>NOT_IN_OSLOVAL_Genefu</th>\n      <th>x_Prolif</th>\n      <th>time</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MB-0000</td>\n      <td>75.65</td>\n      <td>22.0</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>IDC</td>\n      <td>pos</td>\n      <td>+</td>\n      <td>-</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Normal</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2999</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MB-0002</td>\n      <td>43.19</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>IDC</td>\n      <td>pos</td>\n      <td>+</td>\n      <td>+</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>MUT</td>\n      <td>MISSENSE</td>\n      <td>MB-AD-0002+ex5</td>\n      <td>6+chr17:7519122+12521A&gt;AC+178H&gt;H/P+MISSENSE+FR+FR</td>\n      <td>LumA</td>\n      <td>4</td>\n      <td>1</td>\n      <td>ER+/HER2-HighProlif</td>\n      <td>1484</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MB-0005</td>\n      <td>48.87</td>\n      <td>15.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>IDC</td>\n      <td>pos</td>\n      <td>+</td>\n      <td>+</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>LumB</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3053</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MB-0006</td>\n      <td>47.68</td>\n      <td>25.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>IDC</td>\n      <td>pos</td>\n      <td>+</td>\n      <td>+</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>LumB</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1721</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MB-0008</td>\n      <td>76.97</td>\n      <td>40.0</td>\n      <td>8.0</td>\n      <td>3.0</td>\n      <td>IDC</td>\n      <td>pos</td>\n      <td>+</td>\n      <td>+</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>WT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>LumB</td>\n      <td>9</td>\n      <td>1</td>\n      <td>ER+/HER2- High Prolif</td>\n      <td>NaN</td>\n      <td>1241</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 29 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1981 entries, 0 to 1980\nData columns (total 29 columns):\n #   Column                                     Non-Null Count  Dtype  \n---  ------                                     --------------  -----  \n 0   ID                                         1981 non-null   object \n 1   age_at_diagnosis                           1981 non-null   float64\n 2   size                                       1962 non-null   float64\n 3   lymph_nodes_positive                       1975 non-null   float64\n 4   grade                                      1897 non-null   float64\n 5   histological_type                          1981 non-null   object \n 6   ER_IHC_status                              1940 non-null   object \n 7   ER.Expr                                    1981 non-null   object \n 8   PR.Expr                                    1981 non-null   object \n 9   HER2_IHC_status                            821 non-null    float64\n 10  HER2_SNP6_state                            1976 non-null   object \n 11  Her2.Expr                                  1981 non-null   object \n 12  Treatment                                  1981 non-null   object \n 13  NOT_IN_OSLOVAL_menopausal_status_inferred  1970 non-null   object \n 14  NOT_IN_OSLOVAL_group                       1981 non-null   object \n 15  NOT_IN_OSLOVAL_stage                       1534 non-null   float64\n 16  NOT_IN_OSLOVAL_lymph_nodes_removed         1961 non-null   float64\n 17  NOT_IN_OSLOVAL_NPI                         1981 non-null   float64\n 18  NOT_IN_OSLOVAL_cellularity                 1917 non-null   object \n 19  NOT_IN_OSLOVAL_P53_mutation_status         819 non-null    object \n 20  NOT_IN_OSLOVAL_P53_mutation_type           99 non-null     object \n 21  NOT_IN_OSLOVAL_P53_mutation_details        99 non-null     object \n 22  NOT_IN_OSLOVAL_Pam50Subtype                1981 non-null   object \n 23  NOT_IN_OSLOVAL_IntClustMemb                995 non-null    object \n 24  NOT_IN_OSLOVAL_Site                        1981 non-null   int64  \n 25  NOT_IN_OSLOVAL_Genefu                      995 non-null    object \n 26  x_Prolif                                   68 non-null     object \n 27  time                                       1981 non-null   int64  \n 28  status                                     1981 non-null   int64  \ndtypes: float64(8), int64(3), object(18)\nmemory usage: 448.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "source": [
    "# Feature Select Numeric and Categorical"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "featSel=[1,2,3,4,5,6,7,8,10,11,12,13,15,16,17,18,24,27,28]\n",
    "df_sel=df[df.columns[featSel]].copy()\n",
    "\n",
    "colNum=[]\n",
    "colCat=[]\n",
    "#separeta cat and num features\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "for colname in df_sel.columns:\n",
    "    if is_numeric_dtype(df_sel[colname]):\n",
    "        colNum.append(colname)\n",
    "    else:\n",
    "        colCat.append(colname)\n",
    "\n",
    "\n",
    "#sel Num feat\n",
    "df_sel_num=df_sel[colNum].copy()\n",
    "\n",
    "#sel cat feat\n",
    "df_sel_cat=df_sel[colCat].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel_cat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning 1 (Missing Value & Feature Scaling for Numeric Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "\n",
    "\n",
    "#obj imp\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "#obj sca\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "\n",
    "#fit imputer\n",
    "imputer.fit(df_sel_num)\n",
    "#trans\n",
    "arr_sel_num_imp=imputer.transform(df_sel_num)\n",
    "\n",
    "#fit scaling\n",
    "scaler.fit(arr_sel_num_imp)\n",
    "feat_sel_num_imp=scaler.transform(arr_sel_num_imp)\n",
    "\n",
    "\n",
    "df_sel_num_imp=pd.DataFrame(feat_sel_num_imp,columns=df_sel_num.columns)\n",
    "\n",
    "\n",
    "#save and remove status \n",
    "df_status=df_sel_num_imp['status'].copy()\n",
    "df_sel_num_imp=df_sel_num_imp.drop('status',axis=1)\n",
    "feat_sel_num_imp=df_sel_num_imp.to_numpy()\n",
    "df_sel_num_imp.info()\n",
    "feat_sel_num_imp"
   ]
  },
  {
   "source": [
    "# Data Cleaning 2 (Missing Value for Categorical Features)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing data with None (we don't add extra bias)\n",
    "df_sel_cat.fillna('None',inplace=True)\n",
    "df_sel_cat.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Data Cleaning 3 (OneHotEncoder for categoral)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#from cat to ohe\n",
    "encoderOHE=OneHotEncoder(sparse=False)\n",
    "encoderOHE.fit(df_sel_cat)\n",
    "feat_sel_cat=encoderOHE.transform(df_sel_cat)\n",
    "feat_sel_cat"
   ]
  },
  {
   "source": [
    "# Train, Val, Test datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X=np.concatenate((feat_sel_num_imp, feat_sel_cat), axis=1)\n",
    "y=df_status\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y , test_size = 0.2 , random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "source": [
    "# Score Func"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print('Scores:', scores)\n",
    "    print('Mean:', scores.mean())\n",
    "    print('Standard deviation:', scores.std())"
   ]
  },
  {
   "source": [
    "# Classifier ML Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Linear/Logistic Reg"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_reg=LogisticRegression().fit( X_train, y_train )\n",
    "\n",
    "scores = cross_val_score(log_reg, X_train, y_train,scoring='neg_mean_squared_error', cv=10) #greater is better for this -\n",
    "lin_rmse = np.sqrt(-scores)\n",
    "\n",
    "display_scores(lin_rmse)\n"
   ]
  },
  {
   "source": [
    "# Decision Tree"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "scores = cross_val_score(tree_reg, X_train, y_train,scoring='neg_mean_squared_error', cv=10) #greater is better for this -\n",
    "tree_rmse = np.sqrt(-scores)\n",
    "\n",
    "display_scores(tree_rmse)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train,scoring='neg_mean_squared_error', cv=10) #greater is better for this -\n",
    "MLP_rmse = np.sqrt(-scores)\n",
    "\n",
    "display_scores(MLP_rmse)"
   ]
  },
  {
   "source": [
    "# Ensemble Learning: Building a model on top of many other models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "scores = cross_val_score(forest_reg, X_train, y_train,scoring='neg_mean_squared_error', cv=10) #greater is better for this -\n",
    "forest_rmse = np.sqrt(-scores)\n",
    "\n",
    "display_scores(forest_rmse)"
   ]
  },
  {
   "source": [
    "# Grid Search CV\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "     print(np.sqrt(-mean_score), params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forest_reg=RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
    "           max_features=2, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=3, n_jobs=4,\n",
    "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "        \n",
    "scores = cross_val_score(forest_reg, X_train, y_train,scoring='neg_mean_squared_error', cv=10) #greater is better for this -\n",
    "forest_rmse = np.sqrt(-scores)\n",
    "\n",
    "display_scores(forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Random Forest best estimator prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "final_model=grid_search.best_estimator_\n",
    "final_predictions=final_model.predict(X_test)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "#  Visualize features and weights"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "attributes =list(df_sel_num.columns)+list(encoderOHE.get_feature_names())\n",
    "sorted(zip(feature_importances, attributes),reverse=True)"
   ]
  },
  {
   "source": [
    "# Learning Curve"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC as SVM\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(20, 25))\n",
    "\n",
    "title = \"Learning Curves (LogisticRegression)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.0, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "\n",
    "title = \"Learning Curves (SVM)\"\n",
    "estimator = SVM(gamma=0.001)\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 1], ylim=(0.0, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "\n",
    "\n",
    "title = \"Learning Curves (GaussianNB)\"\n",
    "estimator = GaussianNB()\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 2], ylim=(0.0, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "title = \"Learning Curves (DT)\"\n",
    "estimator = DecisionTreeClassifier(max_depth=3)\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 3], ylim=(0.0, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "\n",
    "title = \"Learning Curves (MLP)\"\n",
    "estimator = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 4], ylim=(0.0, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Decision Tree graphviz"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X, y)\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(\n",
    "        tree_clf,\n",
    "        out_file=\"test1.dot\",\n",
    "        feature_names=attributes[:-1],\n",
    "        class_names='status',\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )\n"
   ]
  },
  {
   "source": [
    "# Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Data Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaplanmeier as km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}